{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Transcript from Audio\n",
    "\n",
    "This notebook allows you to process an audio file, split it into clips, and transcribe the content using Whisper.cpp. You can configure the settings using interactive widgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "Configure the input file, output directory, and other settings using interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ebe312193f493b88f518f942172a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../data/audio/full_audio.m4a', description='Input File:', layout=Layout(width='500px'), placeholde‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ffafd29be94751863c6165404efdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../data/output_clips', description='Output Dir:', layout=Layout(width='500px'), placeholder='Enter‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dd605d6e984dd6a11aa546efbeabe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Clip Duration (min):', layout=Layout(width='500px'), max=30, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a51e53b595a4a3899cc39b392ed56bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../whisper.cpp/build/bin/whisper-cli', description='Whisper Exec:', layout=Layout(width='500px'), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58409b0474e046ae862814d630726179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../whisper.cpp/models/ggml-medium.bin', description='Whisper Model:', layout=Layout(width='500px')‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f1c878c4e944e097e6d60b84d9e60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language:', layout=Layout(width='500px'), options=(('Chinese (zh)', 'zh'), ('English (en‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45745da914594f8ab93d358c2fd28dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Transcript File:', layout=Layout(width='500px'), placeholder='Enter transcript fil‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Default configuration values\n",
    "DEFAULT_INPUT_FILE = \"../data/audio/full_audio.m4a\"\n",
    "DEFAULT_OUTPUT_DIR = \"../data/output_clips\"\n",
    "DEFAULT_CLIP_DURATION_MIN = 1  # in minutes\n",
    "DEFAULT_WHISPER_EXEC = \"../whisper.cpp/build/bin/whisper-cli\"\n",
    "DEFAULT_WHISPER_MODEL = \"../whisper.cpp/models/ggml-medium.bin\"\n",
    "DEFAULT_LANGUAGE = \"zh\"\n",
    "DEFAULT_TRANSCRIPT_FILENAME = \"transcription.txt\"\n",
    "\n",
    "# Widgets for configuration\n",
    "input_file_widget = widgets.Text(\n",
    "    value=DEFAULT_INPUT_FILE,\n",
    "    placeholder='Enter input audio file path',\n",
    "    description='Input File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=DEFAULT_OUTPUT_DIR,\n",
    "    placeholder='Enter output directory',\n",
    "    description='Output Dir:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "clip_duration_widget = widgets.IntSlider(\n",
    "    value=DEFAULT_CLIP_DURATION_MIN,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Clip Duration (min):',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_exec_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_EXEC,\n",
    "    placeholder='Enter Whisper.cpp executable path',\n",
    "    description='Whisper Exec:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_model_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_MODEL,\n",
    "    placeholder='Enter Whisper model path',\n",
    "    description='Whisper Model:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "language_widget = widgets.Dropdown(\n",
    "    options=[('Chinese (zh)', 'zh'), ('English (en)', 'en')],\n",
    "    value=DEFAULT_LANGUAGE,\n",
    "    description='Language:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "transcript_filename_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder=f'Enter transcript filename (default: {DEFAULT_TRANSCRIPT_FILENAME})',\n",
    "    description='Transcript File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(input_file_widget)\n",
    "display(output_dir_widget)\n",
    "display(clip_duration_widget)\n",
    "display(whisper_exec_widget)\n",
    "display(whisper_model_widget)\n",
    "display(language_widget)\n",
    "display(transcript_filename_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Audio Processing Functions\n",
    "\n",
    "Import the necessary functions for processing audio files from `voice2transcripts.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the scripts directory to the path so we can import the functions\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n",
    "from voice2transcripts import clear_output_folder, convert_to_wav, split_audio, transcribe_audio\n",
    "from time_stamp_cleaner import read_transcription, clean_transcription, save_cleaned_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Audio and Generate Transcript\n",
    "\n",
    "Run the processing pipeline to convert, split, transcribe, and clean the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Ëº∏Âá∫Ë≥áÊñôÂ§æÂ∑≤Ê∏ÖÈô§ÔºÅ\n",
      "üöÄ ÈñãÂßãÈü≥Ë®äËôïÁêÜËàáËΩâÈåÑÊµÅÁ®ã...\n",
      "üîÑ Èü≥Ë®äÂ∑≤ËΩâÊèõÁÇ∫ WAV Ê†ºÂºèÔºö../data/output_clips/converted.wav\n",
      "‚úÖ Èü≥Ë®äÂàáÂâ≤ÂÆåÊàêÔºåÂÖ± 2 ÂÄãÁâáÊÆµÔºåÊôÇÈñìÊà≥Â∑≤ÂÑ≤Â≠òËá≥ timestamps.txt\n",
      "üé§ ËΩâÈåÑÁâáÊÆµ 1/2: clip_001.wav ...\n",
      "‚ö†Ô∏è Whisper.cpp Ë®äÊÅØ: whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-medium.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51865\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1024\n",
      "whisper_model_load: n_audio_head  = 16\n",
      "whisper_model_load: n_audio_layer = 24\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1024\n",
      "whisper_model_load: n_text_head   = 16\n",
      "whisper_model_load: n_text_layer  = 24\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 4 (medium)\n",
      "whisper_model_load: adding 1608 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_model_load:        Metal total size =  1533.14 MB\n",
      "whisper_model_load: model size    = 1533.14 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4\n",
      "ggml_metal_init: picking default device: Apple M4\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M4\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =   50.33 MB\n",
      "whisper_init_state: kv cross size =  150.99 MB\n",
      "whisper_init_state: kv pad  size  =    6.29 MB\n",
      "whisper_init_state: compute buffer (conv)   =   29.51 MB\n",
      "whisper_init_state: compute buffer (encode) =  170.15 MB\n",
      "whisper_init_state: compute buffer (cross)  =    7.72 MB\n",
      "whisper_init_state: compute buffer (decode) =   99.11 MB\n",
      "\n",
      "system_info: n_threads = 4 / 10 | WHISPER : COREML = 0 | OPENVINO = 0 | Metal : EMBED_LIBRARY = 1 | CPU : ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "\n",
      "main: processing '../data/output_clips/clip_001.wav' (9600000 samples, 600.0 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = zh, task = transcribe, timestamps = 1 ...\n",
      "\n",
      "\n",
      "whisper_print_timings:     load time =   524.76 ms\n",
      "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
      "whisper_print_timings:      mel time =   151.55 ms\n",
      "whisper_print_timings:   sample time =  2353.31 ms /  8015 runs (     0.29 ms per run)\n",
      "whisper_print_timings:   encode time = 15773.04 ms /    23 runs (   685.78 ms per run)\n",
      "whisper_print_timings:   decode time =   439.05 ms /    28 runs (    15.68 ms per run)\n",
      "whisper_print_timings:   batchd time = 26444.84 ms /  7875 runs (     3.36 ms per run)\n",
      "whisper_print_timings:   prompt time =  2754.60 ms /  4753 runs (     0.58 ms per run)\n",
      "whisper_print_timings:    total time = 49001.94 ms\n",
      "ggml_metal_free: deallocating\n",
      "‚úÖ ÁâáÊÆµ 1/2 ËΩâÈåÑÂÆåÊàê\n",
      "üé§ ËΩâÈåÑÁâáÊÆµ 2/2: clip_002.wav ...\n",
      "‚ö†Ô∏è Whisper.cpp Ë®äÊÅØ: whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-medium.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51865\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1024\n",
      "whisper_model_load: n_audio_head  = 16\n",
      "whisper_model_load: n_audio_layer = 24\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1024\n",
      "whisper_model_load: n_text_head   = 16\n",
      "whisper_model_load: n_text_layer  = 24\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 4 (medium)\n",
      "whisper_model_load: adding 1608 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_model_load:        Metal total size =  1533.14 MB\n",
      "whisper_model_load: model size    = 1533.14 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4\n",
      "ggml_metal_init: picking default device: Apple M4\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M4\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =   50.33 MB\n",
      "whisper_init_state: kv cross size =  150.99 MB\n",
      "whisper_init_state: kv pad  size  =    6.29 MB\n",
      "whisper_init_state: compute buffer (conv)   =   29.51 MB\n",
      "whisper_init_state: compute buffer (encode) =  170.15 MB\n",
      "whisper_init_state: compute buffer (cross)  =    7.72 MB\n",
      "whisper_init_state: compute buffer (decode) =   99.11 MB\n",
      "\n",
      "system_info: n_threads = 4 / 10 | WHISPER : COREML = 0 | OPENVINO = 0 | Metal : EMBED_LIBRARY = 1 | CPU : ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "\n",
      "main: processing '../data/output_clips/clip_002.wav' (9097451 samples, 568.6 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = zh, task = transcribe, timestamps = 1 ...\n",
      "\n",
      "\n",
      "whisper_print_timings:     load time =   613.64 ms\n",
      "whisper_print_timings:     fallbacks =   0 p /   2 h\n",
      "whisper_print_timings:      mel time =   159.86 ms\n",
      "whisper_print_timings:   sample time =  1756.75 ms /  4411 runs (     0.40 ms per run)\n",
      "whisper_print_timings:   encode time = 17151.53 ms /    25 runs (   686.06 ms per run)\n",
      "whisper_print_timings:   decode time =  1459.70 ms /    94 runs (    15.53 ms per run)\n",
      "whisper_print_timings:   batchd time = 18035.66 ms /  4195 runs (     4.30 ms per run)\n",
      "whisper_print_timings:   prompt time =  2470.91 ms /  4167 runs (     0.59 ms per run)\n",
      "whisper_print_timings:    total time = 42263.86 ms\n",
      "ggml_metal_free: deallocating\n",
      "‚úÖ ÁâáÊÆµ 2/2 ËΩâÈåÑÂÆåÊàê\n",
      "üéâ ËΩâÈåÑËôïÁêÜÂÆåÊàêÔºÅËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ ../data/output_clips/../transcripts/transcription.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get values from widgets\n",
    "    input_file = input_file_widget.value\n",
    "    output_dir = output_dir_widget.value\n",
    "    clip_duration_sec = clip_duration_widget.value * 60  # Convert minutes to seconds\n",
    "    whisper_exec = whisper_exec_widget.value\n",
    "    whisper_model = whisper_model_widget.value\n",
    "    language = language_widget.value\n",
    "    transcript_filename = transcript_filename_widget.value if transcript_filename_widget.value.strip() else DEFAULT_TRANSCRIPT_FILENAME\n",
    "\n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"‚ùå Êâæ‰∏çÂà∞Ëº∏ÂÖ•Èü≥Ë®äÊ™îÊ°àÔºö{input_file}\")\n",
    "\n",
    "    # Clear old files\n",
    "    clear_output_folder(output_dir)\n",
    "\n",
    "    # Execute the processing pipeline\n",
    "    print(\"üöÄ ÈñãÂßãÈü≥Ë®äËôïÁêÜËàáËΩâÈåÑÊµÅÁ®ã...\")\n",
    "    wav_file = convert_to_wav(input_file, output_dir)\n",
    "    clip_files = split_audio(wav_file, clip_duration_sec, output_dir)\n",
    "    transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename)\n",
    "    print(f\"üéâ ËΩâÈåÑËôïÁêÜÂÆåÊàêÔºÅËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {os.path.join(output_dir, '../transcripts/' + transcript_filename)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ËôïÁêÜÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§Ôºö{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean Transcription\n",
    "\n",
    "Clean the transcription by removing per-sentence timestamps and formatting the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6985c52004968bd770910468c2b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Cleaned Transcript:', layout=Layout(width='500px'), placeholder='Enter cleaned tra‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ ÈñãÂßãÊ∏ÖÁêÜËΩâÈåÑÁµêÊûú...\n",
      "üéâ Ê∏ÖÁêÜÂÆåÊàêÔºÅÊ∏ÖÁêÜÂæåÁöÑËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ ../data/output_clips/../transcripts/clean_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get the transcript file path\n",
    "    transcript_path = os.path.join(output_dir, '../transcripts/' + transcript_filename)\n",
    "    \n",
    "    # Widget for cleaned transcript filename\n",
    "    cleaned_transcript_filename_widget = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter cleaned transcript filename (default: clean_transcription.txt)',\n",
    "        description='Cleaned Transcript:',\n",
    "        layout={'width': '500px'}\n",
    "    )\n",
    "    display(cleaned_transcript_filename_widget)\n",
    "    \n",
    "    # Wait for user input or use default\n",
    "    cleaned_transcript_filename = cleaned_transcript_filename_widget.value if cleaned_transcript_filename_widget.value.strip() else \"clean_transcription.txt\"\n",
    "    cleaned_transcript_path = os.path.join(output_dir, '../transcripts/' + cleaned_transcript_filename)\n",
    "    \n",
    "    # Read, clean, and save the transcription\n",
    "    print(\"üßπ ÈñãÂßãÊ∏ÖÁêÜËΩâÈåÑÁµêÊûú...\")\n",
    "    text = read_transcription(transcript_path)\n",
    "    cleaned_segments = clean_transcription(text)\n",
    "    save_cleaned_transcription(cleaned_segments, cleaned_transcript_path)\n",
    "    print(f\"üéâ Ê∏ÖÁêÜÂÆåÊàêÔºÅÊ∏ÖÁêÜÂæåÁöÑËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {cleaned_transcript_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ê∏ÖÁêÜËΩâÈåÑÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§Ôºö{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
