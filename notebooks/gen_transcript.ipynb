{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Transcript from Audio\n",
    "\n",
    "This notebook allows you to process an audio file, split it into clips, and transcribe the content using Whisper.cpp. You can configure the settings using interactive widgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "Configure the input file, output directory, and other settings using interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Default configuration values\n",
    "# DEFAULT_INPUT_FILE = \"../data//demo/demo.wav\"\n",
    "DEFAULT_INPUT_FILE = \"/Volumes/MacHD/Ê¢µÂÖ¨Â≠ê/Ê¢µÂÖ¨Â≠ê„ÄêÁæéÂ•≥ËµÑÊ∫êÊî∂ÈõÜÂô®„Äë/Á¨¨ÂÖ≠ËäÇ„ÄêËØÜÂà´‚ÄúS‚ÄùÂ•≥„ÄëÂøÖÂê¨/Á¨¨ÂÖ≠ËäÇ„ÄêËØÜÂà´‚Äús‚ÄùÂ•≥„Äë„ÄêWWW.PUACP.COM„Äë.mp4\"\n",
    "DEFAULT_OUTPUT_DIR = \"../data/output_clips\"\n",
    "DEFAULT_CLIP_DURATION_MIN = 1  # in minutes\n",
    "DEFAULT_WHISPER_EXEC = \"../whisper.cpp/build/bin/whisper-cli\"\n",
    "DEFAULT_WHISPER_MODEL = \"../whisper.cpp/models/ggml-medium.bin\"\n",
    "DEFAULT_LANGUAGE = \"zh\"\n",
    "DEFAULT_TRANSCRIPT_FILENAME = \"transcription.txt\"\n",
    "\n",
    "# Widgets for configuration\n",
    "input_file_widget = widgets.Text(\n",
    "    value=DEFAULT_INPUT_FILE,\n",
    "    placeholder='Enter input audio file path',\n",
    "    description='Input File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=DEFAULT_OUTPUT_DIR,\n",
    "    placeholder='Enter output directory',\n",
    "    description='Output Dir:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "clip_duration_widget = widgets.IntSlider(\n",
    "    value=DEFAULT_CLIP_DURATION_MIN,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Clip Duration (min):',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_exec_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_EXEC,\n",
    "    placeholder='Enter Whisper.cpp executable path',\n",
    "    description='Whisper Exec:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_model_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_MODEL,\n",
    "    placeholder='Enter Whisper model path',\n",
    "    description='Whisper Model:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "language_widget = widgets.Dropdown(\n",
    "    options=[('Chinese (zh)', 'zh'), ('English (en)', 'en')],\n",
    "    value=DEFAULT_LANGUAGE,\n",
    "    description='Language:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "transcript_filename_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder=f'Enter transcript filename (default: {DEFAULT_TRANSCRIPT_FILENAME})',\n",
    "    description='Transcript File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(input_file_widget)\n",
    "display(output_dir_widget)\n",
    "display(clip_duration_widget)\n",
    "display(whisper_exec_widget)\n",
    "display(whisper_model_widget)\n",
    "display(language_widget)\n",
    "display(transcript_filename_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Audio Processing Functions\n",
    "\n",
    "Import the necessary functions for processing audio files from `voice2transcripts.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the scripts directory to the path so we can import the functions\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n",
    "from voice2transcripts import clear_output_folder, convert_to_wav, split_audio, transcribe_audio\n",
    "from time_stamp_cleaner import clean_transcription, save_cleaned_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Audio and Generate Transcript\n",
    "\n",
    "Run the processing pipeline to convert, split, transcribe, and clean the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get values from widgets\n",
    "    input_file = input_file_widget.value\n",
    "    output_dir = output_dir_widget.value\n",
    "    clip_duration_sec = clip_duration_widget.value * 60  # Convert minutes to seconds\n",
    "    whisper_exec = whisper_exec_widget.value\n",
    "    whisper_model = whisper_model_widget.value\n",
    "    language = language_widget.value\n",
    "    transcript_filename = transcript_filename_widget.value if transcript_filename_widget.value.strip() else DEFAULT_TRANSCRIPT_FILENAME\n",
    "\n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"‚ùå Êâæ‰∏çÂà∞Ëº∏ÂÖ•Èü≥Ë®äÊ™îÊ°àÔºö{input_file}\")\n",
    "\n",
    "    # Clear old files\n",
    "    clear_output_folder(output_dir)\n",
    "\n",
    "    # Execute the processing pipeline\n",
    "    print(\"üöÄ ÈñãÂßãÈü≥Ë®äËôïÁêÜËàáËΩâÈåÑÊµÅÁ®ã...\")\n",
    "    wav_file = convert_to_wav(input_file, output_dir)\n",
    "    clip_files = split_audio(wav_file, clip_duration_sec, output_dir)\n",
    "    transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename)\n",
    "    print(f\"üéâ ËΩâÈåÑËôïÁêÜÂÆåÊàêÔºÅËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {os.path.join(output_dir, '../transcripts/' + transcript_filename)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ËôïÁêÜÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§Ôºö{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean Transcription\n",
    "\n",
    "Clean the transcription by removing per-sentence timestamps and formatting the content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Configure Cleaned Transcript Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Widget for cleaned transcript filename\n",
    "cleaned_transcript_filename_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter cleaned transcript filename (default: clean_transcription.txt)',\n",
    "    description='Cleaned Transcript:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "display(cleaned_transcript_filename_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Clean and Save Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the transcript file path based on the output directory structure\n",
    "    transcript_dir = os.path.join(os.path.dirname(output_dir), 'transcripts')\n",
    "    transcript_path = os.path.join(transcript_dir, transcript_filename)\n",
    "    \n",
    "    # Get the cleaned transcript filename from the widget\n",
    "    cleaned_transcript_filename = cleaned_transcript_filename_widget.value if cleaned_transcript_filename_widget.value.strip() else \"clean_transcription.txt\"\n",
    "    cleaned_transcript_path = os.path.join(transcript_dir, cleaned_transcript_filename)\n",
    "    \n",
    "    # Read, clean, and save the transcription\n",
    "    print(\"üßπ ÈñãÂßãÊ∏ÖÁêÜËΩâÈåÑÁµêÊûú...\")\n",
    "    print(f\"ÂòóË©¶ËÆÄÂèñËΩâÈåÑÊ™îÊ°àÔºö{transcript_path}\")\n",
    "    if os.path.exists(transcript_path):\n",
    "        print(f\"‚úÖ ÊâæÂà∞ËΩâÈåÑÊ™îÊ°àÔºåÈñãÂßãÊ∏ÖÁêÜ...\")\n",
    "        with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        cleaned_segments = clean_transcription(text)\n",
    "        if cleaned_segments:\n",
    "            save_cleaned_transcription(cleaned_segments, cleaned_transcript_path)\n",
    "            print(f\"üéâ Ê∏ÖÁêÜÂÆåÊàêÔºÅÊ∏ÖÁêÜÂæåÁöÑËΩâÈåÑÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {cleaned_transcript_path}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Ê≤íÊúâÊâæÂà∞ÊúâÊïàÁöÑËΩâÈåÑÂÖßÂÆπÔºåÁÑ°Ê≥ïÂÑ≤Â≠òÊ∏ÖÁêÜÂæåÁöÑÊ™îÊ°à„ÄÇ\")\n",
    "    else:\n",
    "        print(f\"‚ùå ËΩâÈåÑÊ™îÊ°à‰∏çÂ≠òÂú®Ôºö{transcript_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Êâæ‰∏çÂà∞Ê™îÊ°àÔºö{e}\")\n",
    "except IOError as e:\n",
    "    print(f\"‚ùå ËÆÄÂèñÊ™îÊ°àÊôÇÁôºÁîüÈåØË™§Ôºö{e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ê∏ÖÁêÜËΩâÈåÑÈÅéÁ®ã‰∏≠ÁôºÁîüÊú™Áü•ÈåØË™§Ôºö{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Convert Transcript to SRT Format\n",
    "\n",
    "Convert the cleaned transcript into a continuous SRT file format for subtitles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def time_to_srt_format(time_str):\n",
    "    \"\"\"Convert time format from HH:MM:SS to HH:MM:SS,000 for SRT.\"\"\"\n",
    "    if len(time_str.split(':')) == 2:  # Format is MM:SS\n",
    "        time_str = '00:' + time_str\n",
    "    return time_str.replace(':', ':') + ',000'\n",
    "\n",
    "def convert_transcript_to_srt(transcript_path, srt_path):\n",
    "    \"\"\"Convert a transcript file with timestamps to SRT format.\"\"\"\n",
    "    try:\n",
    "        with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Split content into segments based on timestamp headers\n",
    "        segments = re.split(r'\\[(\\d{2}:\\d{2}(?::\\d{2})?) - (\\d{2}:\\d{2}(?::\\d{2})?)\\]\\n', content)\n",
    "        srt_content = []\n",
    "        index = 1\n",
    "        \n",
    "        for i in range(1, len(segments), 3):\n",
    "            start_time = time_to_srt_format(segments[i])\n",
    "            end_time = time_to_srt_format(segments[i+1])\n",
    "            text = segments[i+2].strip()\n",
    "            if text:\n",
    "                srt_content.append(f\"{index}\\n{start_time} --> {end_time}\\n{text}\\n\")\n",
    "                index += 1\n",
    "        \n",
    "        with open(srt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(srt_content))\n",
    "        print(f\"üé¨ SRT file created successfully at: {srt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error converting transcript to SRT: {e}\")\n",
    "\n",
    "# Define paths for transcript and SRT output\n",
    "transcript_dir = os.path.join(os.path.dirname(output_dir), 'transcripts')\n",
    "transcript_path = os.path.join(transcript_dir, transcript_filename)\n",
    "srt_path = os.path.join(transcript_dir, 'subtitles.srt')\n",
    "\n",
    "# Convert transcript to SRT\n",
    "if os.path.exists(transcript_path):\n",
    "    convert_transcript_to_srt(transcript_path, srt_path)\n",
    "else:\n",
    "    print(f\"‚ùå Transcript file does not exist: {transcript_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
