{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Transcript from Audio\n",
    "\n",
    "This notebook allows you to process an audio file, split it into clips, and transcribe the content using Whisper.cpp. You can configure the settings using interactive widgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "Configure the input file, output directory, and other settings using interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Default configuration values\n",
    "DEFAULT_INPUT_FILE = \"./data/audio/full_audio.m4a\"\n",
    "DEFAULT_OUTPUT_DIR = \"./data/output_clips\"\n",
    "DEFAULT_CLIP_DURATION_MIN = 10  # in minutes\n",
    "DEFAULT_WHISPER_EXEC = \"./whisper.cpp/build/bin/whisper-cli\"\n",
    "DEFAULT_WHISPER_MODEL = \"whisper.cpp/models/ggml-medium.bin\"\n",
    "DEFAULT_LANGUAGE = \"zh\"\n",
    "DEFAULT_TRANSCRIPT_FILENAME = \"transcription.txt\"\n",
    "\n",
    "# Widgets for configuration\n",
    "input_file_widget = widgets.Text(\n",
    "    value=DEFAULT_INPUT_FILE,\n",
    "    placeholder='Enter input audio file path',\n",
    "    description='Input File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=DEFAULT_OUTPUT_DIR,\n",
    "    placeholder='Enter output directory',\n",
    "    description='Output Dir:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "clip_duration_widget = widgets.IntSlider(\n",
    "    value=DEFAULT_CLIP_DURATION_MIN,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Clip Duration (min):',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_exec_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_EXEC,\n",
    "    placeholder='Enter Whisper.cpp executable path',\n",
    "    description='Whisper Exec:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_model_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_MODEL,\n",
    "    placeholder='Enter Whisper model path',\n",
    "    description='Whisper Model:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "language_widget = widgets.Dropdown(\n",
    "    options=[('Chinese (zh)', 'zh'), ('English (en)', 'en')],\n",
    "    value=DEFAULT_LANGUAGE,\n",
    "    description='Language:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "transcript_filename_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder=f'Enter transcript filename (default: {DEFAULT_TRANSCRIPT_FILENAME})',\n",
    "    description='Transcript File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(input_file_widget)\n",
    "display(output_dir_widget)\n",
    "display(clip_duration_widget)\n",
    "display(whisper_exec_widget)\n",
    "display(whisper_model_widget)\n",
    "display(language_widget)\n",
    "display(transcript_filename_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Audio Processing Functions\n",
    "\n",
    "Define the functions for processing audio files. These functions are adapted from `voice2transcripts.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "def clear_output_folder(output_dir):\n",
    "    \"\"\"Clear all files and directories in the output folder.\"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        for item in os.listdir(output_dir):\n",
    "            item_path = os.path.join(output_dir, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path):\n",
    "                    os.remove(item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    os.rmdir(item_path)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 無法刪除 {item_path}: {e}\")\n",
    "        print(\"🗑️ 輸出資料夾已清除！\")\n",
    "\n",
    "def convert_to_wav(input_file, output_dir):\n",
    "    \"\"\"Convert input audio/video file to WAV format optimized for Whisper.\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    output_wav = os.path.join(output_dir, \"converted.wav\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", input_file,\n",
    "            \"-ac\", \"1\",        # 單聲道\n",
    "            \"-ar\", \"16000\",    # 16kHz 採樣率 (Whisper 建議)\n",
    "            \"-q:a\", \"0\",       # 最高品質\n",
    "            \"-y\",              # 覆蓋現有檔案\n",
    "            output_wav\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(f\"🔄 音訊已轉換為 WAV 格式：{output_wav}\")\n",
    "        return output_wav\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ 轉換音訊時發生錯誤：{e.stderr}\")\n",
    "        raise\n",
    "\n",
    "def split_audio(input_file, duration_sec, output_dir):\n",
    "    \"\"\"Split audio file into clips of specified duration.\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    clip_files = []\n",
    "    timestamps = []\n",
    "\n",
    "    # 獲取音訊總時長\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-i\", input_file, \"-show_entries\", \"format=duration\",\n",
    "               \"-of\", \"default=noprint_wrappers=1:nokey=1\", \"-v\", \"quiet\"]\n",
    "        total_duration = float(subprocess.check_output(cmd).decode().strip())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ 無法獲取音訊時長：{e}\")\n",
    "        raise\n",
    "\n",
    "    # 切割音訊\n",
    "    for i, start_time in enumerate(range(0, int(total_duration), duration_sec)):\n",
    "        end_time = min(start_time + duration_sec, total_duration)\n",
    "        clip_filename = os.path.join(output_dir, f\"clip_{i+1:03d}.wav\")\n",
    "        \n",
    "        try:\n",
    "            cmd = [\"ffmpeg\", \"-i\", input_file, \"-ss\", str(start_time), \"-t\", str(duration_sec),\n",
    "                   \"-acodec\", \"copy\", \"-y\", clip_filename]\n",
    "            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            \n",
    "            start_time_str = f\"{int(start_time) // 3600:02d}:{(int(start_time) % 3600) // 60:02d}:{int(start_time) % 60:02d}\"\n",
    "            end_time_str = f\"{int(end_time) // 3600:02d}:{(int(end_time) % 3600) // 60:02d}:{int(end_time) % 60:02d}\"\n",
    "            timestamps.append(f\"Clip {i+1}: {start_time_str} - {end_time_str}\\n\")\n",
    "            clip_files.append((clip_filename, start_time, end_time))\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ 切割音訊片段 {i+1} 時發生錯誤：{e.stderr}\")\n",
    "            continue\n",
    "\n",
    "    # 儲存時間戳記\n",
    "    with open(os.path.join(output_dir, \"timestamps.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(timestamps)\n",
    "    \n",
    "    print(f\"✅ 音訊切割完成，共 {len(clip_files)} 個片段，時間戳已儲存至 timestamps.txt\")\n",
    "    return clip_files\n",
    "\n",
    "def transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename=\"transcription.txt\"):\n",
    "    \"\"\"Transcribe audio clips using Whisper.cpp.\n",
    "    \n",
    "    Args:\n",
    "        clip_files: List of tuples containing (clip_filename, start_time, end_time)\n",
    "        output_dir: Directory where audio clips are stored\n",
    "        whisper_exec: Path to Whisper.cpp executable\n",
    "        whisper_model: Path to Whisper model file\n",
    "        language: Language code for transcription\n",
    "        transcript_filename: Name of the output transcript file (default: \\\"transcription.txt\\\")\n",
    "    \"\"\"\n",
    "    transcript_dir = os.path.join(output_dir, \"../transcripts\")\n",
    "    Path(transcript_dir).mkdir(parents=True, exist_ok=True)\n",
    "    transcript_file = os.path.join(transcript_dir, transcript_filename)\n",
    "\n",
    "    # 檢查是否在 Apple Silicon 上執行並且有 Core ML 模型\n",
    "    use_coreml = False\n",
    "    if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "        coreml_model_path = whisper_model.replace(\".bin\", \".mlmodelc\")\n",
    "        if os.path.exists(coreml_model_path):\n",
    "            use_coreml = True\n",
    "            print(\"🍎 使用 Core ML 模型進行轉錄 (Apple Silicon 裝置)\")\n",
    "\n",
    "    with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        total_clips = len(clip_files)\n",
    "        for i, (clip_filename, start_time, end_time) in enumerate(clip_files, 1):\n",
    "            print(f\"🎤 轉錄片段 {i}/{total_clips}: {os.path.basename(clip_filename)} ...\")\n",
    "            cmd = [whisper_exec, \"-m\", whisper_model if not use_coreml else coreml_model_path,\n",
    "                   \"-f\", clip_filename, \"--language\", language]\n",
    "            \n",
    "            if use_coreml:\n",
    "                cmd.append(\"--use-coreml\")\n",
    "\n",
    "            try:\n",
    "                result = subprocess.run(cmd, capture_output=True, text=True, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                text = result.stdout.strip()\n",
    "                if result.stderr:\n",
    "                    print(f\"⚠️ Whisper.cpp 訊息: {result.stderr.strip()}\")\n",
    "\n",
    "                start_time_str = f\"{int(start_time) // 3600:02d}:{(int(start_time) % 3600) // 60:02d}:{int(start_time) % 60:02d}\"\n",
    "                end_time_str = f\"{int(end_time) // 3600:02d}:{(int(end_time) % 3600) // 60:02d}:{int(end_time) % 60:02d}\"\n",
    "                timestamp = f\"[{start_time_str} - {end_time_str}]\"\n",
    "                f.write(f\"{timestamp}\\n{text}\\n\\n\")\n",
    "                print(f\"✅ 片段 {i}/{total_clips} 轉錄完成\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 轉錄片段 {i}/{total_clips} 時發生錯誤: {e}. 繼續處理下一個片段...\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Audio and Generate Transcript\n",
    "\n",
    "Run the processing pipeline to convert, split, and transcribe the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get values from widgets\n",
    "    input_file = input_file_widget.value\n",
    "    output_dir = output_dir_widget.value\n",
    "    clip_duration_sec = clip_duration_widget.value * 60  # Convert minutes to seconds\n",
    "    whisper_exec = whisper_exec_widget.value\n",
    "    whisper_model = whisper_model_widget.value\n",
    "    language = language_widget.value\n",
    "    transcript_filename = transcript_filename_widget.value if transcript_filename_widget.value.strip() else DEFAULT_TRANSCRIPT_FILENAME\n",
    "\n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"❌ 找不到輸入音訊檔案：{input_file}\")\n",
    "\n",
    "    # Clear old files\n",
    "    clear_output_folder(output_dir)\n",
    "\n",
    "    # Execute the processing pipeline\n",
    "    print(\"🚀 開始音訊處理與轉錄流程...\")\n",
    "    wav_file = convert_to_wav(input_file, output_dir)\n",
    "    clip_files = split_audio(wav_file, clip_duration_sec, output_dir)\n",
    "    transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename)\n",
    "    print(f\"🎉 全部處理完成！轉錄結果已儲存至 {os.path.join(output_dir, '../transcripts/' + transcript_filename)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 處理過程中發生錯誤：{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
