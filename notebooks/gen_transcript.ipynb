{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Transcript from Audio\n",
    "\n",
    "This notebook allows you to process an audio file, split it into clips, and transcribe the content using Whisper.cpp. You can configure the settings using interactive widgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "Configure the input file, output directory, and other settings using interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Default configuration values\n",
    "DEFAULT_INPUT_FILE = \"./data/audio/full_audio.m4a\"\n",
    "DEFAULT_OUTPUT_DIR = \"./data/output_clips\"\n",
    "DEFAULT_CLIP_DURATION_MIN = 10  # in minutes\n",
    "DEFAULT_WHISPER_EXEC = \"./whisper.cpp/build/bin/whisper-cli\"\n",
    "DEFAULT_WHISPER_MODEL = \"whisper.cpp/models/ggml-medium.bin\"\n",
    "DEFAULT_LANGUAGE = \"zh\"\n",
    "DEFAULT_TRANSCRIPT_FILENAME = \"transcription.txt\"\n",
    "\n",
    "# Widgets for configuration\n",
    "input_file_widget = widgets.Text(\n",
    "    value=DEFAULT_INPUT_FILE,\n",
    "    placeholder='Enter input audio file path',\n",
    "    description='Input File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=DEFAULT_OUTPUT_DIR,\n",
    "    placeholder='Enter output directory',\n",
    "    description='Output Dir:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "clip_duration_widget = widgets.IntSlider(\n",
    "    value=DEFAULT_CLIP_DURATION_MIN,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Clip Duration (min):',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_exec_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_EXEC,\n",
    "    placeholder='Enter Whisper.cpp executable path',\n",
    "    description='Whisper Exec:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "whisper_model_widget = widgets.Text(\n",
    "    value=DEFAULT_WHISPER_MODEL,\n",
    "    placeholder='Enter Whisper model path',\n",
    "    description='Whisper Model:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "language_widget = widgets.Dropdown(\n",
    "    options=[('Chinese (zh)', 'zh'), ('English (en)', 'en')],\n",
    "    value=DEFAULT_LANGUAGE,\n",
    "    description='Language:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "transcript_filename_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder=f'Enter transcript filename (default: {DEFAULT_TRANSCRIPT_FILENAME})',\n",
    "    description='Transcript File:',\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(input_file_widget)\n",
    "display(output_dir_widget)\n",
    "display(clip_duration_widget)\n",
    "display(whisper_exec_widget)\n",
    "display(whisper_model_widget)\n",
    "display(language_widget)\n",
    "display(transcript_filename_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Audio Processing Functions\n",
    "\n",
    "Define the functions for processing audio files. These functions are adapted from `voice2transcripts.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "def clear_output_folder(output_dir):\n",
    "    \"\"\"Clear all files and directories in the output folder.\"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        for item in os.listdir(output_dir):\n",
    "            item_path = os.path.join(output_dir, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path):\n",
    "                    os.remove(item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    os.rmdir(item_path)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ç„¡æ³•åˆªé™¤ {item_path}: {e}\")\n",
    "        print(\"ğŸ—‘ï¸ è¼¸å‡ºè³‡æ–™å¤¾å·²æ¸…é™¤ï¼\")\n",
    "\n",
    "def convert_to_wav(input_file, output_dir):\n",
    "    \"\"\"Convert input audio/video file to WAV format optimized for Whisper.\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    output_wav = os.path.join(output_dir, \"converted.wav\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", input_file,\n",
    "            \"-ac\", \"1\",        # å–®è²é“\n",
    "            \"-ar\", \"16000\",    # 16kHz æ¡æ¨£ç‡ (Whisper å»ºè­°)\n",
    "            \"-q:a\", \"0\",       # æœ€é«˜å“è³ª\n",
    "            \"-y\",              # è¦†è“‹ç¾æœ‰æª”æ¡ˆ\n",
    "            output_wav\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(f\"ğŸ”„ éŸ³è¨Šå·²è½‰æ›ç‚º WAV æ ¼å¼ï¼š{output_wav}\")\n",
    "        return output_wav\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ è½‰æ›éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e.stderr}\")\n",
    "        raise\n",
    "\n",
    "def split_audio(input_file, duration_sec, output_dir):\n",
    "    \"\"\"Split audio file into clips of specified duration.\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    clip_files = []\n",
    "    timestamps = []\n",
    "\n",
    "    # ç²å–éŸ³è¨Šç¸½æ™‚é•·\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-i\", input_file, \"-show_entries\", \"format=duration\",\n",
    "               \"-of\", \"default=noprint_wrappers=1:nokey=1\", \"-v\", \"quiet\"]\n",
    "        total_duration = float(subprocess.check_output(cmd).decode().strip())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ ç„¡æ³•ç²å–éŸ³è¨Šæ™‚é•·ï¼š{e}\")\n",
    "        raise\n",
    "\n",
    "    # åˆ‡å‰²éŸ³è¨Š\n",
    "    for i, start_time in enumerate(range(0, int(total_duration), duration_sec)):\n",
    "        end_time = min(start_time + duration_sec, total_duration)\n",
    "        clip_filename = os.path.join(output_dir, f\"clip_{i+1:03d}.wav\")\n",
    "        \n",
    "        try:\n",
    "            cmd = [\"ffmpeg\", \"-i\", input_file, \"-ss\", str(start_time), \"-t\", str(duration_sec),\n",
    "                   \"-acodec\", \"copy\", \"-y\", clip_filename]\n",
    "            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            \n",
    "            start_time_str = f\"{int(start_time) // 3600:02d}:{(int(start_time) % 3600) // 60:02d}:{int(start_time) % 60:02d}\"\n",
    "            end_time_str = f\"{int(end_time) // 3600:02d}:{(int(end_time) % 3600) // 60:02d}:{int(end_time) % 60:02d}\"\n",
    "            timestamps.append(f\"Clip {i+1}: {start_time_str} - {end_time_str}\\n\")\n",
    "            clip_files.append((clip_filename, start_time, end_time))\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ åˆ‡å‰²éŸ³è¨Šç‰‡æ®µ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e.stderr}\")\n",
    "            continue\n",
    "\n",
    "    # å„²å­˜æ™‚é–“æˆ³è¨˜\n",
    "    with open(os.path.join(output_dir, \"timestamps.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(timestamps)\n",
    "    \n",
    "    print(f\"âœ… éŸ³è¨Šåˆ‡å‰²å®Œæˆï¼Œå…± {len(clip_files)} å€‹ç‰‡æ®µï¼Œæ™‚é–“æˆ³å·²å„²å­˜è‡³ timestamps.txt\")\n",
    "    return clip_files\n",
    "\n",
    "def transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename=\"transcription.txt\"):\n",
    "    \"\"\"Transcribe audio clips using Whisper.cpp.\n",
    "    \n",
    "    Args:\n",
    "        clip_files: List of tuples containing (clip_filename, start_time, end_time)\n",
    "        output_dir: Directory where audio clips are stored\n",
    "        whisper_exec: Path to Whisper.cpp executable\n",
    "        whisper_model: Path to Whisper model file\n",
    "        language: Language code for transcription\n",
    "        transcript_filename: Name of the output transcript file (default: \\\"transcription.txt\\\")\n",
    "    \"\"\"\n",
    "    transcript_dir = os.path.join(output_dir, \"../transcripts\")\n",
    "    Path(transcript_dir).mkdir(parents=True, exist_ok=True)\n",
    "    transcript_file = os.path.join(transcript_dir, transcript_filename)\n",
    "\n",
    "    # æª¢æŸ¥æ˜¯å¦åœ¨ Apple Silicon ä¸ŠåŸ·è¡Œä¸¦ä¸”æœ‰ Core ML æ¨¡å‹\n",
    "    use_coreml = False\n",
    "    if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "        coreml_model_path = whisper_model.replace(\".bin\", \".mlmodelc\")\n",
    "        if os.path.exists(coreml_model_path):\n",
    "            use_coreml = True\n",
    "            print(\"ğŸ ä½¿ç”¨ Core ML æ¨¡å‹é€²è¡Œè½‰éŒ„ (Apple Silicon è£ç½®)\")\n",
    "\n",
    "    with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        total_clips = len(clip_files)\n",
    "        for i, (clip_filename, start_time, end_time) in enumerate(clip_files, 1):\n",
    "            print(f\"ğŸ¤ è½‰éŒ„ç‰‡æ®µ {i}/{total_clips}: {os.path.basename(clip_filename)} ...\")\n",
    "            cmd = [whisper_exec, \"-m\", whisper_model if not use_coreml else coreml_model_path,\n",
    "                   \"-f\", clip_filename, \"--language\", language]\n",
    "            \n",
    "            if use_coreml:\n",
    "                cmd.append(\"--use-coreml\")\n",
    "\n",
    "            try:\n",
    "                result = subprocess.run(cmd, capture_output=True, text=True, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                text = result.stdout.strip()\n",
    "                if result.stderr:\n",
    "                    print(f\"âš ï¸ Whisper.cpp è¨Šæ¯: {result.stderr.strip()}\")\n",
    "\n",
    "                start_time_str = f\"{int(start_time) // 3600:02d}:{(int(start_time) % 3600) // 60:02d}:{int(start_time) % 60:02d}\"\n",
    "                end_time_str = f\"{int(end_time) // 3600:02d}:{(int(end_time) % 3600) // 60:02d}:{int(end_time) % 60:02d}\"\n",
    "                timestamp = f\"[{start_time_str} - {end_time_str}]\"\n",
    "                f.write(f\"{timestamp}\\n{text}\\n\\n\")\n",
    "                print(f\"âœ… ç‰‡æ®µ {i}/{total_clips} è½‰éŒ„å®Œæˆ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è½‰éŒ„ç‰‡æ®µ {i}/{total_clips} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}. ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹ç‰‡æ®µ...\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Audio and Generate Transcript\n",
    "\n",
    "Run the processing pipeline to convert, split, and transcribe the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get values from widgets\n",
    "    input_file = input_file_widget.value\n",
    "    output_dir = output_dir_widget.value\n",
    "    clip_duration_sec = clip_duration_widget.value * 60  # Convert minutes to seconds\n",
    "    whisper_exec = whisper_exec_widget.value\n",
    "    whisper_model = whisper_model_widget.value\n",
    "    language = language_widget.value\n",
    "    transcript_filename = transcript_filename_widget.value if transcript_filename_widget.value.strip() else DEFAULT_TRANSCRIPT_FILENAME\n",
    "\n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"âŒ æ‰¾ä¸åˆ°è¼¸å…¥éŸ³è¨Šæª”æ¡ˆï¼š{input_file}\")\n",
    "\n",
    "    # Clear old files\n",
    "    clear_output_folder(output_dir)\n",
    "\n",
    "    # Execute the processing pipeline\n",
    "    print(\"ğŸš€ é–‹å§‹éŸ³è¨Šè™•ç†èˆ‡è½‰éŒ„æµç¨‹...\")\n",
    "    wav_file = convert_to_wav(input_file, output_dir)\n",
    "    clip_files = split_audio(wav_file, clip_duration_sec, output_dir)\n",
    "    transcribe_audio(clip_files, output_dir, whisper_exec, whisper_model, language, transcript_filename)\n",
    "    print(f\"ğŸ‰ å…¨éƒ¨è™•ç†å®Œæˆï¼è½‰éŒ„çµæœå·²å„²å­˜è‡³ {os.path.join(output_dir, '../transcripts/' + transcript_filename)}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
